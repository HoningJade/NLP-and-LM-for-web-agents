{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f41304d-34f4-4031-a2f0-1e166bd34dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28a1370-db07-4922-943a-4a59896057f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/mind2web.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202c373c-0b54-4f4d-bb60-1e9ab6c6330a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5532 529483 1382 133051\n",
      "Objective: Check for pickup restaurant available in Boston, NY on March 18, 5pm with just one guest.\n",
      "Element: [168] combobox '' hasPopup: menu expanded: False\n",
      "Objective: Check for pickup restaurant available in Boston, NY on March 18, 5pm with just one guest.\n",
      "Element: [1] RootWebArea '' focused: True\n"
     ]
    }
   ],
   "source": [
    "negative_examples = []\n",
    "positive_examples = []\n",
    "negative_examples_id = []\n",
    "positive_examples_id = []\n",
    "val_negative_examples = []\n",
    "val_positive_examples = []\n",
    "val_negative_examples_id = []\n",
    "val_positive_examples_id = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    ex = df.iloc[i]\n",
    "    elements = [el.strip() for el in ex['OBSERVATION'].split('\\n')]\n",
    "    action_string = ex['ACTION']\n",
    "    objective = ex['OBJECTIVE']\n",
    "    \n",
    "    match = re.search(r'\\[(\\d+)\\]', action_string)\n",
    "    groundtruth_id = match.group(1) if match else None\n",
    "    if groundtruth_id:\n",
    "        gt_id_formatted = f'[{groundtruth_id}]'\n",
    "        for x in elements:\n",
    "            if gt_id_formatted in x:\n",
    "                # positive_examples.append((objective, x))\n",
    "                if i < len(df) * 0.8:\n",
    "                    positive_examples.append(f'Objective: {objective}.\\nElement: {x}')\n",
    "                    positive_examples_id.append(i)\n",
    "                else:\n",
    "                    val_positive_examples.append(f'Objective: {objective}.\\nElement: {x}')\n",
    "                    val_positive_examples_id.append(i)\n",
    "            else:\n",
    "                if i < len(df) * 0.8:\n",
    "                    negative_examples.append(f'Objective: {objective}.\\nElement: {x}')\n",
    "                    negative_examples_id.append(i)\n",
    "                else:\n",
    "                    val_negative_examples.append(f'Objective: {objective}.\\nElement: {x}')\n",
    "                    val_negative_examples_id.append(i)\n",
    "\n",
    "print(len(positive_examples), len(negative_examples), len(val_positive_examples), len(val_negative_examples))\n",
    "print(positive_examples[0])\n",
    "print(negative_examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c455a0e-7bd2-4e61-a5e0-77b67aa126c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535015 134433\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create DataFrame\n",
    "train_df = pd.DataFrame(data = {\n",
    "    'id': positive_examples_id + negative_examples_id,\n",
    "    'text': positive_examples + negative_examples,\n",
    "    'label': [1] * len(positive_examples) + [-1] * len(negative_examples)\n",
    "})\n",
    "val_df = pd.DataFrame(data = {\n",
    "    'id': val_positive_examples_id + val_negative_examples_id,\n",
    "    'text': val_positive_examples + val_negative_examples,\n",
    "    'label': [1] * len(val_positive_examples) + [-1] * len(val_negative_examples)\n",
    "})\n",
    "\n",
    "# TODO(jykoh): Change to 1.0 later\n",
    "train_df = train_df.sample(frac=1.0).reset_index(drop=True)  # Shuffle\n",
    "val_df = val_df#.sample(frac=0.005).reset_index(drop=True)\n",
    "print(len(train_df), len(val_df))\n",
    "\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "val_df.to_csv('val_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0004b0ba-f31a-433b-bab5-2f22e1157686",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c70d08d-d51d-4f15-b48b-fdf34b7a9a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DebertaTokenizer\n",
    "\n",
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc492e6-2972-4b90-9529-5c14d88320c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c72caf87f484b14b61017dcc2aa987b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/535015 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490c914e840a42b2a0114e84e0e96931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/134433 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DebertaTokenizer\n",
    "from datasets import Dataset\n",
    "import random\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
    "\n",
    "# Function to tokenize a batch of texts\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "# Convert your pandas dataframes to Hugging Face Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "# Tokenize the data\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddab3247-4f1a-4d54-9fd5-59d8f236ac50",
   "metadata": {},
   "source": [
    "Balance dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2095c28a-267e-4f9d-ba49-4388c32f7d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d755d46ccc764f32a0d8ffbb2b175905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/535015 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02126fafb8234a189407759f449a3315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/535015 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_dataset = tokenized_train_dataset.filter(lambda example: example['label'] == 1)\n",
    "negative_dataset = tokenized_train_dataset.filter(lambda example: example['label'] == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a09d108-a4a0-48cf-8bb8-6b99eb973c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/jingyuk/elm/lib/python3.10/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/scratch/jingyuk/elm/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# Function to create subsets of the negative dataset\n",
    "def create_negative_subsets(dataset, subset_size, num_subsets):\n",
    "    subsets = []\n",
    "    for _ in range(num_subsets):\n",
    "        # Randomly sample without replacement\n",
    "        sampled_indices = random.sample(range(len(dataset)), subset_size)\n",
    "        subsets.append(dataset.select(sampled_indices))\n",
    "    return subsets\n",
    "\n",
    "positive_count, negative_count = len(positive_dataset), len(negative_dataset)\n",
    "sampling_ratio = negative_count // positive_count\n",
    "\n",
    "negative_subsets = create_negative_subsets(negative_dataset, positive_count, sampling_ratio)\n",
    "balanced_datasets = [concatenate_datasets([positive_dataset, neg_subset]).shuffle() for neg_subset in negative_subsets]\n",
    "combined_balanced_dataset = concatenate_datasets(balanced_datasets).shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadfb95a-cc90-4724-bdec-5d68c6615845",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8df825ea-71d5-4671-aa08-3a5966026df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.weight', 'classifier.weight', 'classifier.bias', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification\n",
    "\n",
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
    "model = DebertaForSequenceClassification.from_pretrained('microsoft/deberta-base', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1857d4f2-1d4d-4dff-a966-134b4dd4a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        eval_dataset = eval_dataset or self.eval_dataset\n",
    "        # Call the original evaluate function\n",
    "        predictions = self.predict(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "        # Convert logits to predicted labels\n",
    "        predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "        # Aggregate predictions and true labels by ID\n",
    "        id_recall = {}\n",
    "        for idx, id_ in enumerate(eval_dataset['id']):\n",
    "            if id_ not in id_recall:\n",
    "                id_recall[id_] = {'logits': [], 'preds': [], 'labels': []}\n",
    "\n",
    "            id_recall[id_]['logits'].append(predictions.predictions[idx, 1])\n",
    "            id_recall[id_]['preds'].append(predicted_labels[idx])\n",
    "            id_recall[id_]['labels'].append(predictions.label_ids[idx])\n",
    "\n",
    "        output = {}\n",
    "        # Compute recall for each ID\n",
    "        for k in [5, 10, 50]:\n",
    "            total_recalled = 0\n",
    "            total = 0\n",
    "            for id_, data in id_recall.items():\n",
    "                # Sort the logits and get top k indices\n",
    "                top_k_indices = sorted(range(len(data['logits'])), key=lambda i: data['logits'][i], reverse=True)[:k]\n",
    "                # Get the labels corresponding to the top k logits\n",
    "                top_k_labels = [data['labels'][i] for i in top_k_indices]\n",
    "                if 1 in top_k_labels:\n",
    "                    total_recalled += 1\n",
    "                if 1 in data['labels']:\n",
    "                    total += 1\n",
    "            output[f'r@{k}'] = total_recalled / total\n",
    "\n",
    "        if self.args.logging_dir is not None:\n",
    "            tb_writer = SummaryWriter(log_dir=self.args.logging_dir)\n",
    "            # Log each ID's recall to TensorBoard\n",
    "            for k, score in output.items():\n",
    "                tb_writer.add_scalar(f\"eval/{k}\", score, self.state.global_step)\n",
    "            tb_writer.flush()\n",
    "            tb_writer.close()\n",
    "\n",
    "        # Add aggregated recall scores to output\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad87e510-1bfe-4ed2-807f-caef5aea2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    print(accuracy_score(labels, predictions))\n",
    "    return {'accuracy': accuracy_score(labels, predictions)}\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./deberta_results',          # directory for storing logs and model checkpoints\n",
    "    num_train_epochs=3,              # number of training epochs\n",
    "    per_device_train_batch_size=32,  # batch size for training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type= \"cosine\",\n",
    "    weight_decay=0.001,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    report_to=\"tensorboard\",\n",
    "    bf16=True,\n",
    "    logging_steps=100,                # log model metrics every 'logging_steps' steps\n",
    "    evaluation_strategy=\"steps\",     # evaluation strategy to adopt during training\n",
    "    eval_steps=500,                  # number of steps to run evaluation\n",
    "    load_best_model_at_end=True      # load the best model when finished training\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=combined_balanced_dataset,  # Use your combined balanced dataset\n",
    "    eval_dataset=tokenized_val_dataset,        # Validation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf3ad7-5019-4f45-bbb5-2775a99567cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='501' max='98541' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  501/98541 06:56 < 22:42:16, 1.20 it/s, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='2101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  20/2101 00:09 < 17:39, 1.96 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02626a42-2d05-4240-9416-0bbec4ccd0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
