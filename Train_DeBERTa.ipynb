{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f41304d-34f4-4031-a2f0-1e166bd34dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0f47c6-5f7d-44c3-8d14-8dc4436654bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DebertaTokenizer\n",
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202c373c-0b54-4f4d-bb60-1e9ab6c6330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = 'data/mind2web.csv'\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# negative_examples = []\n",
    "# positive_examples = []\n",
    "# negative_examples_id = []\n",
    "# positive_examples_id = []\n",
    "# val_negative_examples = []\n",
    "# val_positive_examples = []\n",
    "# val_negative_examples_id = []\n",
    "# val_positive_examples_id = []\n",
    "\n",
    "# for i in range(len(df)):\n",
    "#     ex = df.iloc[i]\n",
    "#     elements = [el.strip() for el in ex['OBSERVATION'].split('\\n')]\n",
    "#     action_string = ex['ACTION']\n",
    "#     objective = ex['OBJECTIVE']\n",
    "    \n",
    "#     match = re.search(r'\\[(\\d+)\\]', action_string)\n",
    "#     groundtruth_id = match.group(1) if match else None\n",
    "#     if groundtruth_id:\n",
    "#         gt_id_formatted = f'[{groundtruth_id}]'\n",
    "#         for x in elements:\n",
    "#             if gt_id_formatted in x:\n",
    "#                 # positive_examples.append((objective, x))\n",
    "#                 if i < len(df) * 0.8:\n",
    "#                     positive_examples.append(f'Objective: {objective}.\\nElement: {x}')\n",
    "#                     positive_examples_id.append(i)\n",
    "#                 else:\n",
    "#                     val_positive_examples.append(f'Objective: {objective}.\\nElement: {x}')\n",
    "#                     val_positive_examples_id.append(i)\n",
    "#             else:\n",
    "#                 if i < len(df) * 0.8:\n",
    "#                     negative_examples.append(f'Objective: {objective}.\\nElement: {x}')\n",
    "#                     negative_examples_id.append(i)\n",
    "#                 else:\n",
    "#                     val_negative_examples.append(f'Objective: {objective}.\\nElement: {x}')\n",
    "#                     val_negative_examples_id.append(i)\n",
    "\n",
    "# print(len(positive_examples), len(negative_examples), len(val_positive_examples), len(val_negative_examples))\n",
    "# print(positive_examples[0])\n",
    "# print(negative_examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c455a0e-7bd2-4e61-a5e0-77b67aa126c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Create DataFrame\n",
    "# train_df = pd.DataFrame(data = {\n",
    "#     'id': positive_examples_id + negative_examples_id,\n",
    "#     'text': positive_examples + negative_examples,\n",
    "#     'label': [1] * len(positive_examples) + [-1] * len(negative_examples)\n",
    "# })\n",
    "# val_df = pd.DataFrame(data = {\n",
    "#     'id': val_positive_examples_id + val_negative_examples_id,\n",
    "#     'text': val_positive_examples + val_negative_examples,\n",
    "#     'label': [1] * len(val_positive_examples) + [-1] * len(val_negative_examples)\n",
    "# })\n",
    "\n",
    "# # TODO(jykoh): Change to 1.0 later\n",
    "# train_df = train_df.sample(frac=1.0).reset_index(drop=True)  # Shuffle\n",
    "# val_df = val_df#.sample(frac=0.005).reset_index(drop=True)\n",
    "# print(len(train_df), len(val_df))\n",
    "\n",
    "# train_df.to_csv('train_data.csv', index=False)\n",
    "# val_df.to_csv('val_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc492e6-2972-4b90-9529-5c14d88320c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DebertaTokenizer\n",
    "# from datasets import Dataset\n",
    "# import random\n",
    "# from datasets import concatenate_datasets\n",
    "\n",
    "# # Load the tokenizer\n",
    "# tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
    "\n",
    "# # Function to tokenize a batch of texts\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "# # Convert your pandas dataframes to Hugging Face Dataset objects\n",
    "# train_dataset = Dataset.from_pandas(train_df)\n",
    "# val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "# # Tokenize the data\n",
    "# tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "# tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# positive_dataset = tokenized_train_dataset.filter(lambda example: example['label'] == 1)\n",
    "# negative_dataset = tokenized_train_dataset.filter(lambda example: example['label'] == -1)\n",
    "\n",
    "# # Function to create subsets of the negative dataset\n",
    "# def create_negative_subsets(dataset, subset_size, num_subsets):\n",
    "#     subsets = []\n",
    "#     for _ in range(num_subsets):\n",
    "#         # Randomly sample without replacement\n",
    "#         sampled_indices = random.sample(range(len(dataset)), subset_size)\n",
    "#         subsets.append(dataset.select(sampled_indices))\n",
    "#     return subsets\n",
    "\n",
    "# positive_count, negative_count = len(positive_dataset), len(negative_dataset)\n",
    "# sampling_ratio = negative_count // positive_count\n",
    "\n",
    "# negative_subsets = create_negative_subsets(negative_dataset, positive_count, sampling_ratio)\n",
    "# balanced_datasets = [concatenate_datasets([positive_dataset, neg_subset]).shuffle() for neg_subset in negative_subsets]\n",
    "# combined_balanced_dataset = concatenate_datasets(balanced_datasets).shuffle()\n",
    "\n",
    "# combined_balanced_dataset.save_to_disk('train.hf')\n",
    "# tokenized_val_dataset.save_to_disk('val.hf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddab3247-4f1a-4d54-9fd5-59d8f236ac50",
   "metadata": {},
   "source": [
    "Balance dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "407b3cd7-f3ec-454a-8237-b17c46380667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/jingyuk/elm/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "combined_balanced_dataset = load_from_disk('train.hf')\n",
    "tokenized_val_dataset = load_from_disk('val.hf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0004b0ba-f31a-433b-bab5-2f22e1157686",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadfb95a-cc90-4724-bdec-5d68c6615845",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8df825ea-71d5-4671-aa08-3a5966026df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification\n",
    "\n",
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
    "model = DebertaForSequenceClassification.from_pretrained('microsoft/deberta-base', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1857d4f2-1d4d-4dff-a966-134b4dd4a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        # compute custom loss (suppose one has 3 labels with different weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), ((labels + 1) // 2).view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        eval_dataset = eval_dataset or self.eval_dataset\n",
    "        # Call the original evaluate function\n",
    "        predictions = self.predict(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "        # Convert logits to predicted labels\n",
    "        predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Aggregate predictions and true labels by ID\n",
    "        id_recall = {}\n",
    "        bce_loss = []\n",
    "        for idx, id_ in enumerate(eval_dataset['id']):\n",
    "            if id_ not in id_recall:\n",
    "                id_recall[id_] = {'logits': [], 'preds': [], 'labels': []}\n",
    "\n",
    "            id_recall[id_]['logits'].append(predictions.predictions[idx, 1])\n",
    "            id_recall[id_]['preds'].append(predicted_labels[idx])\n",
    "            id_recall[id_]['labels'].append(predictions.label_ids[idx])\n",
    "\n",
    "            label = predictions.label_ids[idx]\n",
    "            logits = predictions.predictions[idx]\n",
    "            bce_loss.append(loss_fct(torch.tensor([logits]), torch.tensor([int(label == 1)])))\n",
    "\n",
    "        mean_bce_loss = torch.mean(torch.stack(bce_loss))\n",
    "\n",
    "        output = {\n",
    "            'eval_loss': mean_bce_loss.item()\n",
    "        }\n",
    "        # Compute recall for each ID\n",
    "        for k in [1, 5, 10, 50]:\n",
    "            total_recalled = 0\n",
    "            total = 0\n",
    "            total_recalled_random = 0\n",
    "            for id_, data in id_recall.items():\n",
    "                # Sort the logits and get top k indices\n",
    "                top_k_indices = sorted(range(len(data['logits'])), key=lambda i: data['logits'][i], reverse=True)[:k]\n",
    "                # Get the labels corresponding to the top k logits\n",
    "                top_k_labels = [data['labels'][i] for i in top_k_indices]\n",
    "                if 1 in top_k_labels:\n",
    "                    total_recalled += 1\n",
    "                if 1 in [data['labels'][i] for i in random.sample(range(0, len(data['labels'])), min(k, len(data['labels'])))]:\n",
    "                    total_recalled_random += 1\n",
    "                if 1 in data['labels']:\n",
    "                    total += 1\n",
    "            output[f'r@{k}'] = total_recalled / total\n",
    "            output[f'r_rand@{k}'] = total_recalled_random / total\n",
    "\n",
    "        if self.args.logging_dir is not None:\n",
    "            tb_writer = SummaryWriter(log_dir=self.args.logging_dir)\n",
    "            # Log each ID's recall to TensorBoard\n",
    "            for k, score in output.items():\n",
    "                tb_writer.add_scalar(f\"eval/{k}\", score, self.state.global_step)\n",
    "            tb_writer.flush()\n",
    "            tb_writer.close()\n",
    "\n",
    "        # Add aggregated recall scores to output\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad87e510-1bfe-4ed2-807f-caef5aea2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import datasets\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    print(accuracy_score(labels, predictions))\n",
    "    return {'accuracy': accuracy_score(labels, predictions)}\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./deberta_results',          # directory for storing logs and model checkpoints\n",
    "    num_train_epochs=3,              # number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size for training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type= \"cosine\",\n",
    "    weight_decay=0.001,               # strength of weight decay\n",
    "    report_to=\"tensorboard\",\n",
    "    bf16=True,\n",
    "    logging_steps=100,                # log model metrics every 'logging_steps' steps\n",
    "    evaluation_strategy=\"steps\",     # evaluation strategy to adopt during training\n",
    "    eval_steps=1000,                  # number of steps to run evaluation\n",
    "    save_steps=1000,\n",
    "    load_best_model_at_end=True      # load the best model when finished training\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=combined_balanced_dataset,  # Use your combined balanced dataset\n",
    "    eval_dataset=tokenized_val_dataset,        # Validation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf3ad7-5019-4f45-bbb5-2775a99567cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3627' max='197079' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  3627/197079 1:19:51 < 71:01:19, 0.76 it/s, Epoch 0.06/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2101' max='2101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2101/2101 17:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009261118921693335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3199613/140405029.py:41: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  bce_loss.append(loss_fct(torch.tensor([logits]), torch.tensor([int(label == 1)])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008799922638042742\n",
      "0.00892637968355984\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a27b20-e163-45cf-9f88-eaace74a87aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
